This was an learning project that served the purpose of getting familiar with the transformer architecture. The task was to classify audio files into two content types. Someone with an interest in this functionality or an interest in learning might have a use for it, but it is massive computational overkill to compare thousands of frame-vectors to another in a transformer to classify audio segments. A transformer is not the right architecture for this task. The project is a continuation of the abandoned [audio-similarity](https://github.com/Taylor-eOS/audio-similarity).
The later project [sltm-classifier](https://github.com/Taylor-eOS/sltm-classifier) worked better.
